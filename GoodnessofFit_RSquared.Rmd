---
title: "RSquared Challenged!"

description: R-squared does not measure goodness of fit. It can be arbitrarily low when the model is completely correct.
author:
  - name: Lesson by Dr. Joshua O.S.Hunt, Mississippi State University
          Interpreted by Tracy Morgan  
date: "`r Sys.Date()`"
output: distill::distill_article
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
#### R-Squared works a bit like a grading system in stats.  The values of R-Squared range from 0 to 1.  Think of this like a 100%, if the R-Squared is higher (closer to 100%), then our model is doing a good job explaining the variation in our data.  If the number is lower, then our model is only explaining a lower percentage of the actual data Most programs will give you R-Squared as an output when running summary statistics becuase it is well-known as an important and accurate measurement.

#### One theory combatting this belief is that R-Squared is not always a measure of good fit within a model.  This code and lesson is from Dr. Joshua O.S. Hunt of Mississippi State University.    

---

**In R, we typically get R-squared by calling the summary function on a model object. Here’s a quick example using simulated data:**

```{r,echo=TRUE}
# independent variable
x <- 1:20 
# for reproducibility
set.seed(1) 
# dependent variable; function of x with random error
y <- 2 + 0.5*x + rnorm(20,0,3) 
# simple linear regression
mod <- lm(y~x)
# request just the r-squared value
summary(mod)$r.squared   
```
 
**One way to express R-squared is as the sum of squared fitted-value deviations divided by the sum of squared original-value deviations**
 
$$ R^{2} =  \frac{\sum (\hat{y} – \bar{\hat{y}})^{2}}{\sum (y – \bar{y})^{2}}$$
 
 
```{r}
 # extract fitted (or predicted) values from model
f <- mod$fitted.values
# sum of squared fitted-value deviations
mss <- sum((f - mean(f))^2)
# sum of squared original-value deviations
tss <- sum((y - mean(y))^2)
# r-squared
mss/tss 
```
### In the previous formula, prediction is f.  We calculated each predition minus the mean of the prediction and then we squared it and summed it and then we did the same for the actual which gives us RSquared.  

**R-squared does not measure goodness of fit. It can be arbitrarily low when the model is completely correct.** 

**Assertion:**  By making the variance (sigma squared) larger, we drive R-squared towards 0.  This is not good! This happens even when every assumption of the simple linear regression model is correct.

$$σ2$$
---
We can demonstrate that this is a problem.  Let's make a function called r2.0 that will increase the variance and show how that affects R-squared.  "sig" represents our input and our function will make x values and y values wit sig (our input) being the standard deviation. This is how we can make the variance larger or smaller.  Then summary will pull up R-squared.  

Sigmas are the sequences which will go from .5 to 20. You can see the variables when when you run signmas, which shows us our increasing standard deviation. 

Rout is a function that is taking each signma and put it into the r2.0 function.  The sapply function runs each sigma through this canned loop. 

When we run rout, we see R-Squared for each signma.  R-Square tanks going from .98 to .009!  All we did was to increase the standard deviation.  Keep in mind, nothing is wrong with this model, all we changed was the spread of x.  


```{r}
r2.0 <- function(sig){
  # our predictor
  x <- seq(1,10,length.out = 100)   
  # our response; a function of x plus some random noise
  y <- 2 + 1.2*x + rnorm(100,0,sd = sig) 
  # print the R-squared value
  summary(lm(y ~ x))$r.squared          
}
sigmas <- seq(0.5,20,length.out = 20)
 # apply our function to a series of sigma values
rout <- sapply(sigmas, r2.0)            
plot(rout ~ sigmas, type="b")


```

**In summary, all we did was increase the standard deviation for a model and R-Squared changed dramatically.  This proves that is not always a measure of good fit.**








